# Graphcore Roadmap：AI 芯片
> 学习笔记 | 版本：1.0 | 2026-02-03

---

## 一、公司概况

### 1.1 业务定位

```
Graphcore 业务架构

┌─────────────────────────────────────────────────────────┐
│                   Graphcore plc                       │
├─────────────────┬─────────────────┬─────────────────────┤
│   IPU 芯片      │   系统方案      │   软件生态          │
├─────────────────┬─────────────────┼─────────────────────┤
| • IPU-M2000    | • IPU-POD      | • Poplar SDK       |
| • IPU-M2000   | • 数据中心     | • PyTorch/TF      |
| • 下一代      | • 云计算       | • 开发者支持       |
└─────────────────┴─────────────────┴─────────────────────┘
```

### 1.2 核心优势

| 优势 | 说明 |
|------|------|
| **IPU 架构** | 区别于 GPU 的全新架构 |
| **大规模并行** | 适合稀疏计算 |
| **内存架构** | 高带宽片上存储 |
| **欧洲背景** | 英国公司，美系外选择 |

---

## 二、IPU 产品演进

### 2.1 产品时间线

| 产品 | 制程 | 算力 (TFLOPS) | 片上存储 | 应用 | 时间 |
|------|------|---------------|----------|------|------|
| **GC2** | 16nm | 250 | 300MB | 训练/推理 | 2020 |
| **GC200** | 7nm | 500 | 900MB | 训练/推理 | 2021 |
| **BOW IPU** | 7nm | 550 | 1GB | 训练/推理 | 2023 |
| **下一代** | 5nm | 2000 | 4GB | 训练/推理 | 2025 |

### 2.2 GC200 规格

| 参数 | 规格 | 说明 |
|------|------|------|
| **制程** | 7nm (TSMC) | 先进制程 |
| **架构** | IPU-Core | 独立架构 |
| **算力** | 500 TFLOPS (FP16) | 高算力 |
| **片上存储** | 900MB | 高带宽 |
| **互连** | IPU-Link | 芯片互联 |
| **功耗** | 300W | TDP |

### 2.3 IPU 架构特点

| 特点 | 说明 |
|------|------|
| **大规模并行** | 1472 个核心 |
| **细粒度计算** | 支持稀疏计算 |
| **片上存储** | 900MB 高带宽 |
| **低精度支持** | FP8/FP16/INT8 |

---

## 三、BOW IPU

### 3.1 性能提升

| 指标 | GC200 | BOW IPU | 提升 |
|------|--------|---------|------|
| **算力** | 500 TFLOPS | 550 TFLOPS | +10% |
| **能效** | 1.7 TFLOPS/W | 2.2 TFLOPS/W | +30% |
| **片上存储** | 900MB | 1GB | +11% |
| **支持** | 训练/推理 | 训练/推理 | 相同 |

### 3.2 应用场景

| 场景 | 性能表现 | 说明 |
|------|----------|------|
| **Transformer** | 优秀 | 适合大模型 |
| **CNN** | 优秀 | 传统 AI |
| **稀疏模型** | 极佳 | 架构优势 |
| **推荐系统** | 优秀 | 稀疏计算 |

---

## 四、软件生态

### 4.1 Poplar SDK

| 组件 | 功能 | 说明 |
|------|------|------|
| **Poplar** | 运行时 | IPU 运行时 |
| **PopART** | 框架 | ONNX 运行时 |
| **Poptorch** | PyTorch | 集成 |
| **TensorFlow** | TF Hub | 支持 |

### 4.2 框架支持

| 框架 | 支持程度 | 说明 |
|------|----------|------|
| **PyTorch** | ✅ 完整 | 官方支持 |
| **TensorFlow** | ✅ 完整 | 官方支持 |
| **JAX** | ✅ | 实验支持 |
| **ONNX** | ✅ | 通用格式 |

---

## 五、竞争分析

### 5.1 vs NVIDIA

| 指标 | Graphcore | H100 | 差距 |
|------|-----------|------|------|
| **算力** | 550 TFLOPS | 2000 TFLOPS | 4x |
| **显存** | 1GB (片上) | 80GB (HBM) | 劣势 |
| **软件** | 发展中 | 成熟 CUDA | 劣势 |
| **价格** | $40K | $30K | 劣势 |

### 5.2 vs Google TPU

| 指标 | Graphcore | TPU v5p | 差距 |
|------|-----------|---------|------|
| **算力** | 550 TFLOPS | 2000 TFLOPS | 4x |
| **生态** | 发展中 | 成熟 | 劣势 |
| **灵活性** | 高 | 低 | 优势 |
| **价格** | $40K | $4.5/小时 | 模式不同 |

---

## 六、营收与市场

### 6.1 营收预测

| 年份 | 营收 | 增速 | 客户数 |
|------|------|------|--------|
| **2024** | $0.1B | +25% | 50+ |
| **2025** | $0.15B | +50% | 100+ |
| **2026** | $0.25B | +67% | 200+ |

### 6.2 主要客户

| 客户类型 | 特点 | 应用 |
|----------|------|------|
| **学术机构** | 早期用户 | 研究 |
| **欧洲企业** | 数据本地化 | AI 研究 |
| **美国企业** | 替代选择 | 特定场景 |

---

## 七、学习要点

### 7.1 核心数据

| 数据 | 数值 |
|------|------|
| BOW IPU 算力 | 550 TFLOPS |
| 片上存储 | 1GB |
| 2024 营收 | $0.1B |
| 架构 | IPU (独立) |

### 7.2 关键趋势

1. **IPU 架构**：区别于 GPU
2. **稀疏计算**：架构优势
3. **欧洲背景**：美系外选择
4. **规模有限**：市场较小

---

## 八、延伸学习

### 8.1 待追踪问题

1. 下一代 IPU 何时发布？
2. 能否突破 NVIDIA 垄断？
3. 软件生态进展？
4. 中国市场策略？

### 8.2 推荐研究

1. NVIDIA GPU 架构
2. Google TPU 架构
3. Cerebras 架构
4. AI 芯片竞争格局

---

*本学习笔记由 Clawdbot 自主学习整理*
*版本：1.0 | 2026-02-03*
