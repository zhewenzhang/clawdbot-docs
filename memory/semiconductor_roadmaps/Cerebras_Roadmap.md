# Cerebras Systems Roadmap：AI 芯片
> 学习笔记 | 版本：1.0 | 2026-02-03

---

## 一、公司概况

### 1.1 业务定位

```
Cerebras 业务架构

┌─────────────────────────────────────────────────────────┐
│                   Cerebras Systems                     │
├─────────────────┬─────────────────┬─────────────────────┤
│   Wafer-Scale   │   云服务       │   本地部署          │
│   Engine (WSE)  | • Cerebras Cloud| • CS-2/CS-3       │
│   超大芯片      | • AI 训练      | • 企业部署          │
└─────────────────┴─────────────────┴─────────────────────┘
```

### 1.2 核心优势

| 优势 | 说明 |
|------|------|
| **晶圆级芯片** | 全球最大芯片 |
| **内存带宽** | 极高带宽 |
| **集群扩展** | 万亿参数 |
| **大模型训练** | 速度极快 |

---

## 二、Wafer-Scale Engine 系列

### 2.1 产品演进

| 产品 | 制程 | 晶体管 | 片上存储 | 算力 | 时间 |
|------|------|--------|----------|------|------|
| **WSE-1** | 14nm | 1.2T | 18GB | 2 PLOPS | 2019 |
| **WSE-2** | 7nm | 2.6T | 40GB | 4 PLOPS | 2021 |
| **WSE-3** | 5nm | 4.0T | 80GB | 8 PLOPS | 2024 |
| **WSE-4** | 3nm | 8.0T | 160GB | 16 PLOPS | 2026 |

### 2.2 WSE-3 规格

| 参数 | 规格 | 说明 |
|------|------|------|
| **制程** | 5nm (TSMC) | 先进制程 |
| **尺寸** | 46225 mm² | 晶圆级 |
| **晶体管** | 4.0T | 全球最大 |
| **核心数** | 900,000 | 90 万核 |
| **片上存储** | 80GB | SRAM |
| **带宽** | 21 PB/s | 极高 |
| **功耗** | 15kW | TDP |

### 2.3 芯片对比

| 指标 | WSE-3 | H100 | 差距 |
|------|-------|------|------|
| **面积** | 46225mm² | 814mm² | 57x |
| **晶体管** | 4.0T | 80B | 50x |
| **核心数** | 900K | 16896 | 53x |
| **片上存储** | 80GB | 80GB | 相同 |
| **算力** | 8 PLOPS | 2 PLOPS | 4x |

---

## 三、系统产品

### 3.1 CS-2/3 系统

| 系统 | 芯片 | 算力 | 内存 | 功耗 | 时间 |
|------|------|------|------|------|------|
| **CS-2** | WSE-2 | 4 PLOPS | 40GB | 20kW | 2021 |
| **CS-3** | WSE-3 | 8 PLOPS | 80GB | 25kW | 2024 |
| **CS-4** | WSE-4 | 16 PLOPS | 160GB | 35kW | 2026 |

### 3.2 集群能力

| 配置 | 参数 | 应用 |
|------|------|------|
| **单节点** | 8 PLOPS | 大模型 |
| **64 节点** | 512 PLOPS | 万亿参数 |
| **128 节点** | 1 EFLOPS | 超大模型 |

---

## 四、 Andromeda 集群

### 4.1 集群规格

| 参数 | 规格 | 说明 |
|------|------|------|
| **节点数** | 16-64 | 可扩展 |
| **总算力** | 64-256 PLOPS | 超大规模 |
| **存储** | PB 级 | 高性能 |
| **网络** | InfiniBand | 低延迟 |
| **位置** | 美国 | 云端 |

### 4.2 大模型训练

| 模型 | 参数 | 训练时间 | 对比 GPU |
|------|------|----------|----------|
| **GPT-3** | 175B | 2 天 | 3 个月 |
| **GPT-4** | 1T | 5 天 | 6 个月 |
| **Llama 2** | 70B | 1 天 | 1 个月 |

---

## 五、软件生态

### 5.1 Cerebras Software Stack

| 组件 | 功能 | 说明 |
|------|------|------|
| **CS-ware** | 框架 | 深度学习框架 |
| **PyTorch** | 框架 | 官方支持 |
| **TensorFlow** | 框架 | 支持 |
| **Sparsity** | 稀疏计算 | 加速 |

### 5.2 框架支持

| 框架 | 支持程度 | 特点 |
|------|----------|------|
| **PyTorch** | ✅ 完整 | 推荐使用 |
| **TensorFlow** | ✅ | 支持 |
| **JAX** | ✅ | 研发中 |
| **Megatron** | ✅ | 分布式 |

---

## 六、竞争分析

### 6.1 vs NVIDIA

| 指标 | Cerebras | H100 | 差距 |
|------|-----------|------|------|
| **算力** | 8 PLOPS | 2 PLOPS | 4x |
| **内存** | 80GB | 80GB | 相同 |
| **扩展性** | 万亿参数 | 千亿参数 | 10x |
| **价格** | $2M/节点 | $30K | 67x |
| **灵活性** | 低 | 高 | 劣势 |

### 6.2 vs Google TPU

| 指标 | Cerebras | TPU v5p | 差距 |
|------|-----------|---------|------|
| **算力** | 8 PLOPS | 2 PLOPS | 4x |
| **内存** | 80GB | 128GB | 劣势 |
| **部署** | 云/本地 | 仅云 | 优势 |
| **生态** | 发展中 | 成熟 | 劣势 |

---

## 七、营收与市场

### 7.1 营收预测

| 年份 | 营收 | 增速 | 客户数 |
|------|------|------|--------|
| **2024** | $0.25B | +100% | 50+ |
| **2025** | $0.5B | +100% | 100+ |
| **2026** | $1B | +100% | 200+ |

### 7.2 客户结构

| 客户类型 | 占比 | 说明 |
|----------|------|------|
| **科研机构** | 40% | 学术研究 |
| **科技巨头** | 30% | AI 研发 |
| **药企** | 20% | 药物发现 |
| **政府** | 10% | 国家 AI |

---

## 八、学习要点

### 8.1 核心数据

| 数据 | 数值 |
|------|------|
| WSE-3 晶体管 | 4.0T |
| WSE-3 算力 | 8 PLOPS |
| 芯片面积 | 46225 mm² |
| 核心数 | 90 万核 |

### 8.2 关键趋势

1. **晶圆级芯片**：全球最大
2. **大模型训练**：速度极快
3. **集群扩展**：万亿参数
4. **高成本**：价格昂贵

---

## 九、延伸学习

### 9.1 待追踪问题

1. WSE-4 何时发布？
2. 大模型普及？
3. 能否挑战 NVIDIA？
4. 中国市场策略？

### 9.2 推荐研究

1. NVIDIA GPU 架构
2. Graphcore IPU
3. Google TPU
4. 大模型训练成本

---

*本学习笔记由 Clawdbot 自主学习整理*
*版本：1.0 | 2026-02-03*
