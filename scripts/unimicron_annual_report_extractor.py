#!/usr/bin/env python3
"""
æ¬£å…´ç”µå­å¹´æŠ¥ä¸‹è½½ä¸ä¿¡æ¯æå–å·¥å…·
åŠŸèƒ½ï¼š
1. ç³»ç»Ÿæ€§æœç´¢å¹´æŠ¥PDF
2. ä¸‹è½½å¹¶æå–å…³é”®ä¿¡æ¯
3. å®šä½"å¤§é™†å­å…¬å¸ä¿¡æ¯æŠ«éœ²"é¡µé¢
4. æˆªå›¾ä¿å­˜å…³é”®é¡µé¢
"""

import requests
import re
import os
import json
from datetime import datetime

headers = {
    'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36'
}

def search_unimicron_annual_reports():
    """æœç´¢æ¬£å…´ç”µå­å†å¹´è´¢æŠ¥"""
    
    # å¯èƒ½çš„å¹´æŠ¥URLæ¨¡å¼
    url_patterns = [
        # å°æ¹¾å…¬å¼€èµ„è®¯è§‚æµ‹ç«™
        'https://mops.twse.com.tw/mops/web/ajax_t164sb04_e?firstin=true&year={year}&co_id=3037',
        # æ¬£å…´å®˜ç½‘
        'https://www.unimicron.com/files/money/Shareholders_Meeting/{year}-annual_en.pdf',
        # é›ªçƒ
        'https://stockn.xueqiu.com/00631/{yyyymmdd}.pdf',
    ]
    
    # æœç´¢å…³é”®è¯
    search_queries = [
        'æ¬£èˆˆé›»å­ 2024 å¹´å ± PDF',
        'Unimicron 2024 annual report Taiwan',
        '3037 å¹´å ± PDF ä¸‹è¼‰',
    ]
    
    print("ğŸ“Š æœç´¢æ¬£å…´ç”µå­å†å¹´è´¢æŠ¥...")
    
    # å°è¯•ç›´æ¥è®¿é—®å¯èƒ½çš„URL
    for year in [2024, 2023, 2022, 2021]:
        yyyy = str(year)
        yyyymmdd = f"{year}1231" if year <= 2024 else f"{year-1}1231"
        
        for pattern in url_patterns:
            url = pattern.format(year=year, yyyy=yyyy, yyyymmdd=yyyymmdd)
            try:
                r = requests.head(url, headers=headers, timeout=10, allow_redirects=True)
                if r.status_code == 200:
                    print(f"âœ… å¯èƒ½å­˜åœ¨: {url[:80]}")
                    return url  # è¿”å›æ‰¾åˆ°çš„URL
            except:
                pass
    
    return None

def extract_china_subsidiary_info(pdf_path):
    """
    ä»PDFä¸­æå–"å¤§é™†å­å…¬å¸ä¿¡æ¯æŠ«éœ²"
    å…³é”®ç« èŠ‚é€šå¸¸åœ¨ï¼š
    - éåˆä½µè²¡å‹™å ±å‘Šä¹‹å­å…¬å¸è²¡å‹™è³‡è¨Š
    - å¤§é™¸å­å…¬å¸è³‡è¨Šæ­éœ²
    - ä¸»è¦å¾€ä¾†éŠ€è¡Œæˆä¿¡é¡åº¦
    """
    
    import subprocess
    
    # ä½¿ç”¨ pdftotext æå–æ–‡æœ¬
    try:
        result = subprocess.run(
            ['pdftotext', '-layout', pdf_path, '-'],
            capture_output=True,
            text=True
        )
        text = result.stdout
        
        # æœç´¢å…³é”®ç« èŠ‚
        keywords = [
            'å¤§é™¸å­å…¬å¸',
            'éåˆä½µè²¡å‹™å ±å‘Šä¹‹å­å…¬å¸',
            'å¤§é™¸å­å…¬å¸è³‡è¨Šæ­éœ²',
            'å­å…¬å¸',
            'é™„å±¬å…¬å¸'
        ]
        
        found_sections = []
        for keyword in keywords:
            if keyword in text:
                # æå–å…³é”®è¯é™„è¿‘çš„æ–‡æœ¬
                pattern = rf'{keyword}[^\n]{{0,500}}'
                matches = re.findall(pattern, text)
                if matches:
                    for match in matches[:5]:  # æœ€å¤šæå–5æ¡
                        found_sections.append(match.strip())
        
        return found_sections[:10]  # è¿”å›æœ€å¤š10æ¡
        
    except Exception as e:
        print(f"âŒ æå–å¤±è´¥: {e}")
        return []

def extract_last_pages(pdf_path, num_pages=5):
    """æå–PDFæœ€åå‡ é¡µ"""
    
    import subprocess
    
    total_pages = subprocess.run(
        ['pdfinfo', pdf_path],
        capture_output=True,
        text=True
    )
    
    # è§£ææ€»é¡µæ•°
    for line in total_pages.stdout.split('\n'):
        if line.startswith('Pages:'):
            total = int(line.split(':')[1].strip())
            print(f"ğŸ“„ PDFæ€»é¡µæ•°: {total}")
            break
    
    # ä½¿ç”¨ pdftotext æå–æœ€åå‡ é¡µ
    last_pages_text = []
    for i in range(num_pages, 0, -1):
        page_num = total - i + 1
        try:
            result = subprocess.run(
                ['pdftotext', '-f', str(page_num), '-l', str(page_num), pdf_path, '-'],
                capture_output=True,
                text=True
            )
            content = result.stdout.strip()
            if content:
                last_pages_text.append(f"--- ç¬¬ {page_num} é¡µ ---")
                last_pages_text.append(content[:3000])  # æ¯é¡µæœ€å¤š3000å­—ç¬¦
        except Exception as e:
            print(f"âŒ æå–ç¬¬{page_num}é¡µå¤±è´¥: {e}")
    
    return '\n\n'.join(last_pages_text)

if __name__ == '__main__':
    # æµ‹è¯•ï¼šä½¿ç”¨2020å¹´å¹´æŠ¥
    pdf_path = '/tmp/unimicron_annual_2020.pdf'
    
    if os.path.exists(pdf_path):
        print("=" * 60)
        print("ğŸ“Š æµ‹è¯•ï¼šæå–2020å¹´å¹´æŠ¥æœ€åå‡ é¡µ")
        print("=" * 60)
        
        # æå–æœ€åå‡ é¡µ
        last_pages = extract_last_pages(pdf_path, num_pages=5)
        
        if last_pages:
            print(f"\nğŸ“„ æœ€å5é¡µå†…å®¹é¢„è§ˆ:")
            print("-" * 60)
            print(last_pages[:5000])
            print("-" * 60)
            
            # æœç´¢å¤§é™†å­å…¬å¸ä¿¡æ¯
            china_info = extract_china_subsidiary_info(pdf_path)
            
            if china_info:
                print(f"\nâœ… æ‰¾åˆ° {len(china_info)} æ¡ç›¸å…³ä¿¡æ¯:")
                for i, info in enumerate(china_info[:5], 1):
                    print(f"\n{i}. {info[:500]}")
            else:
                print("\nâŒ æœªæ‰¾åˆ°å¤§é™†å­å…¬å¸ä¿¡æ¯æŠ«éœ²")
    else:
        print(f"âŒ PDFä¸å­˜åœ¨: {pdf_path}")
