# 09 | DeepSeek 为什么能这么便宜？

---

## 一、一个震撼的数字

| 模型 | 训练成本 |
|-----|---------|
| GPT-4 | $1 亿+ |
| Claude | $1 亿+ |
| **DeepSeek-V3** | **$557 万** |

**同样是顶级 AI，成本差 18 倍！**

为什么？

---

## 二、AI 训练成本拆解

### 2.1 成本构成

| 成本项 | 占比 |
|-------|------|
| 算力（GPU） | 70-80% |
| 数据 | 10-20% |
| 人力 | 5-10% |
| 其他 | 5% |

**关键是降低算力成本。**

---

## 三、DeepSeek 的降本绝招

### 3.1 第一招：MoE（节省 90% 计算）

| 模型类型 | 计算量 | 激活参数 |
|---------|-------|---------|
| 全参数模型 | 高 | 100% |
| **DeepSeekMoE** | 低 | ~6% |

### 3.2 第二招：MLA（节省 50% 内存）

| 方法 | KV 缓存 | 内存 |
|-----|--------|-----|
| 标准 | 大 | 高 |
| **MLA** | 小 | **省 50%+** |

### 3.3 第三招：FP8 训练（节省 30% 内存）

| 精度 | 内存占用 | 计算速度 |
|-----|---------|---------|
| FP16 | 基准 | 基准 |
| **FP8** | **省 30%** | **快 2x** |

### 3.4 第四招：DualPipe（隐藏通信）

| 方法 | GPU 利用率 |
|-----|-----------|
| 标准流水线 | 低 |
| **DualPipe** | **高** |

---

## 四、成本对比表

| 维度 | GPT-4 | DeepSeek-V3 |
|-----|-------|-------------|
| 训练成本 | $1 亿+ | $557 万 |
| 推理成本/百万 tokens | $60 | $0.14 |
| 所需 GPU | 数万张 | 约 2000 张 |
| 能耗 | 高 | **低 90%** |

---

## 五、降本带来的影响

### 5.1 对行业

- AI 从"贵族"变"平民"
- 更多玩家入场
- 竞争加剧

### 5.2 对用户

- API 价格下降
- 免费服务增多
- AI 普及加速

### 5.3 对社会

- AI 门槛降低
- 创新门槛降低
- 机会更平等

---

## 六、未来成本趋势

| 年份 | 预期变化 |
|-----|---------|
| 2025 | 成本继续下降 50% |
| 2026 | 可能再降 50% |
| 2027 | AI 成本接近零？ |

---

## 七、总结

1. **MoE + MLA + FP8 + DualPipe** 四大降本绝招
2. **成本降 90%**，效果不打折
3. **意义深远**：AI 普及加速

---

**下篇预告**：《DeepSeek 的下一步：AGI 之路》

---

**作者**: 可乐
**更新时间**: 2026-02-02
**系列**: DeepSeek 技术科普系列 #09
